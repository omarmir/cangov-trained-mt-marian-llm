{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ecf8847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from time import sleep\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d43df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"ai_test.json\"\n",
    "OUTPUT_CLEAN = \"ai_test_clean.json\"\n",
    "OUTPUT_REJECTED = \"ai_test_rejected.json\"\n",
    "MODEL = \"mistral:instruct\"\n",
    "SCORE_THRESHOLD = 3  # Reject if score <= this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9c47347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(prompt: str) -> str:\n",
    "    process = subprocess.run(\n",
    "        [r\"C:\\Users\\MIRO1\\AppData\\Local\\Programs\\Ollama\\ollama.exe\", \"run\", MODEL],\n",
    "        input=prompt.encode(),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        timeout=60,\n",
    "    )\n",
    "    return process.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(en, fr):\n",
    "    return f\"\"\"\n",
    "You are a bilingual translation reviewer.\n",
    "\n",
    "Given the following English sentence and its French translation:\n",
    "\n",
    "English: \"{en}\"\n",
    "French: \"{fr}\"\n",
    "\n",
    "Evaluate the quality of the French translation and provide your response in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"score\": <integer from 1 to 5>,\n",
    "  \"fr\": \"<corrected French translation or 'REJECTED: <reason>'>\"\n",
    "}}\n",
    "\n",
    "Scoring Criteria:\n",
    "- 5: Excellent (accurate and fluent)\n",
    "- 4: Good (minor grammar/style issues or spelling mistakes)\n",
    "- 3: Fair (noticeable errors)\n",
    "- 2: Poor (many errors)\n",
    "- 1: Bad (completely incorrect)\n",
    "\n",
    "Only output the JSON object. Do not include any explanations or additional text.\n",
    "Use â€™ instead of ' when writing contractions in french.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bd93d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response: str):\n",
    "    try:\n",
    "        data = json.loads(response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return None, None, f\"Invalid JSON: {e}\"\n",
    "\n",
    "    # Validate the presence of 'score' and 'fr' keys\n",
    "    if 'score' not in data or 'fr' not in data:\n",
    "        return None, None, \"Missing 'score' or 'fr' in response\"\n",
    "\n",
    "    score = data['score']\n",
    "    fr = data['fr']\n",
    "\n",
    "    # Ensure 'score' is an integer\n",
    "    if not isinstance(score, int):\n",
    "        return None, None, \"Score is not an integer\"\n",
    "\n",
    "    # Check if the translation was rejected\n",
    "    if isinstance(fr, str) and fr.strip().upper().startswith(\"REJECTED\"):\n",
    "        return score, None, fr.strip()\n",
    "\n",
    "    return score, fr.strip(), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec517ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLEANED] Line 1 (Score: 5)\n",
      "[CLEANED] Line 2 (Score: 5)\n",
      "[CLEANED] Line 3 (Score: 4)\n",
      "[CLEANED] Line 4 (Score: 5)\n",
      "[REJECTED] Line 5 (Score: 1) - REJECTED: This translation does not accurately reflect the original English sentence\n"
     ]
    }
   ],
   "source": [
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f_in, \\\n",
    "     open(OUTPUT_CLEAN, \"w\", encoding=\"utf-8\") as f_clean, \\\n",
    "     open(OUTPUT_REJECTED, \"w\", encoding=\"utf-8\") as f_reject:\n",
    "\n",
    "    data = json.load(f_in)\n",
    "    clean_results = []\n",
    "    reject_results = []\n",
    "\n",
    "    for i, row in enumerate(data):\n",
    "        en = row[\"en\"]\n",
    "        fr = row[\"fr\"]\n",
    "        prompt = build_prompt(en, fr)\n",
    "        try:\n",
    "            response = query_ollama(prompt)\n",
    "            score, corrected, reason = parse_response(response)\n",
    "            if score is None:\n",
    "                print(f\"[ERROR] Line {i+1}: {reason}\")\n",
    "                continue\n",
    "            if corrected:\n",
    "                clean_results.append({\"en\": en, \"fr\": corrected, \"score\": score, \"original\": row[\"fr\"]})\n",
    "                print(f\"[CLEANED] Line {i+1} (Score: {score})\")\n",
    "            else:\n",
    "                reject_results.append({\"en\": en, \"fr\": fr, \"score\": score, \"reason\": reason})\n",
    "                print(f\"[REJECTED] Line {i+1} (Score: {score}) - {reason}\")\n",
    "            sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Line {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    json.dump(clean_results, f_clean, ensure_ascii=False, indent=2)\n",
    "    json.dump(reject_results, f_reject, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
